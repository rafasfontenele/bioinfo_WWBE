{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python script to obtain Usher tree data and process it for use into the WWBE pipeline\n",
    "\n",
    "* Every time this code is ran it will get the latest version of the Usher tree, this is why we have the date as the required option to include when running the script. This will generate two output files containing the SNVs associated with each lineage of the SARS-CoV-2 phylogenetic tree. One does not include clade names and the other includes lineage and clade names. It will also create a lineage annotated tree that could be used in iTOL.\n",
    "\n",
    "partial code adapted from freyja code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import subprocess\n",
    "import urllib.request\n",
    "import os\n",
    "from ete3 import PhyloTree\n",
    "import logging, time\n",
    "\n",
    "#this function updates the Usher tree file\n",
    "def download_tree(locDir):\n",
    "\turl = \"http://hgdownload.soe.ucsc.edu/goldenPath/wuhCor1/\"\\\n",
    "\t          \"UShER_SARS-CoV-2/public-latest.all.masked.pb.gz\"\n",
    "\ttreePath = os.path.join(locDir, \"public-latest.all.masked.pb.gz\")\n",
    "\turllib.request.urlretrieve(url, treePath)\n",
    "\treturn treePath\n",
    "\n",
    "# this function generates the files to from the Usher tree\n",
    "def generate_files_from_tree(TreePath):\n",
    "    cmd_lineagepath = f\"matUtils extract -i {TreePath} -C lineagePaths.txt\"\n",
    "    cmd_allpaths = f\"matUtils extract -i {TreePath} -A all_Paths.txt\"\n",
    "    cmd_nwktree = f\"matUtils extract -i {TreePath} -t Usher_fulltree.nwk\"\n",
    "    sys.stdout.flush()  # force python to flush\n",
    "    completed_lin = subprocess.run(cmd_lineagepath, shell=True, executable=\"/bin/bash\",\n",
    "                               stdout=subprocess.DEVNULL)\n",
    "    completed_all = subprocess.run(cmd_allpaths, shell=True, executable=\"/bin/bash\",\n",
    "                               stdout=subprocess.DEVNULL)\n",
    "    completed_tree = subprocess.run(cmd_nwktree, shell=True, executable=\"/bin/bash\",\n",
    "                               stdout=subprocess.DEVNULL)\n",
    "    return completed_lin, completed_all, completed_tree\n",
    "\n",
    "# this function edits the all_paths.txt \n",
    "def edit_all_paths():\n",
    "    df = pd.DataFrame()\n",
    "    with open(\"all_Paths.txt\", \"r\") as file:\n",
    "        keep=[line for line in file]\n",
    "        nodes_name=[info.split(\":\")[0] for info in keep]\n",
    "        nodes_snvs=[info.split(\":\")[1].strip(\" \").rstrip() for info in keep]\n",
    "        df[\"Nodes\"] = nodes_name\n",
    "        df[\"SNVs\"] = nodes_snvs\n",
    "    df.to_csv(\"node_snvs_all.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "#auxiliar function\n",
    "def fix(x):\n",
    "    to_add =[]\n",
    "    to_remove =[]\n",
    "    for mut in x:\n",
    "        if \",\" in mut:\n",
    "            to_remove.append(mut)\n",
    "            for nmut in mut.split(\",\"):\n",
    "                to_add.append(nmut)\n",
    "    x = x + to_add\n",
    "    x = [item for item in x if item not in to_remove]\n",
    "    return x\n",
    "\n",
    "# this function formats the lineagePaths.txt file to turn the snvs info into a list\n",
    "def parse_tree_paths(df, clade):\n",
    "    df = df.set_index('clade')\n",
    "    #take out nextrain clade name\n",
    "    if clade == \"clade_out\":\n",
    "        nxNames = df.index[df.index.str[0].str.isdigit()]\n",
    "        df = df.drop(index=nxNames)\n",
    "    # Make sure to check with new tree versions, lineages could get trimmed.\n",
    "    df = df.drop_duplicates(keep='last')\n",
    "    df['from_tree_root'] = df['from_tree_root'].fillna('')\n",
    "    df['from_tree_root'] = df['from_tree_root']\\\n",
    "        .apply(lambda x: x.replace(' ', '').strip('>').split('>'))\n",
    "    df['from_tree_root'] = df['from_tree_root']\\\n",
    "        .apply(fix)\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename(columns={\"clade\":\"Lineage\", \"from_tree_root\":\"SNVs\"})\n",
    "    return df\n",
    "\n",
    "#This function (written by Yiyan) prepares the Usher tree to keep lineage node only\n",
    "def create_lineage_tree_for_itol():\n",
    "    cmd_info= f\"cut -f2 lineagePaths.txt | tail -n +2 | sort | uniq > lineage_nodes\"\n",
    "    sys.stdout.flush()\n",
    "    completed = subprocess.run(cmd_info, shell=True, executable=\"/bin/bash\",\n",
    "                               stdout=subprocess.DEVNULL)\n",
    "    tree = PhyloTree(\"Usher_fulltree.nwk\", format=3)\n",
    "    with open(\"lineage_nodes\") as f:\n",
    "        node_list = f.read().splitlines()\n",
    "    for node in tree.traverse(\"postorder\"):\n",
    "        if node.is_leaf() and node.name not in node_list:\n",
    "            node.detach()\n",
    "    for node in tree.traverse(\"postorder\"):\n",
    "        if node.up:\n",
    "            parent = node.up\n",
    "            if len(parent.get_children())==1 and (not node.name in node_list) and (not node.is_leaf()):\n",
    "                for child in node.get_children():\n",
    "                    parent.add_child(child)\n",
    "                parent.remove_child(node)\n",
    "    tree.write(format=3, outfile=\"lineage_tree.nwk\", format_root_node=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    date = sys.argv[1]\n",
    "    logger = logging.getLogger(__name__)\n",
    "    locDir = os.path.abspath(os.path.join(os.path.realpath(__file__),\n",
    "\t                                         os.pardir))\n",
    "    new_path = os.path.join(locDir, date)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)\n",
    "        os.chdir(new_path)\n",
    "    else:\n",
    "        logger.warning('Outpath already exists and will be overwritten!')\n",
    "    os.chdir(new_path)\n",
    "    TreePath = download_tree(new_path)\n",
    "    generate_files_from_tree(TreePath)\n",
    "    edit_all_paths()\n",
    "    df = pd.read_csv(\"/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/Usher_processing/\"+str(date)+\"/lineagePaths.txt\", sep=\"\\t\")\n",
    "    clade = \"clade\"\n",
    "    file_clade = parse_tree_paths(df, clade)\n",
    "    file_clade.to_csv(\"lineagePaths_edited_clades_\"+str(date)+\".tsv\", sep=\"\\t\", index=False)\n",
    "    file_clade.to_pickle(\"lineagePaths_edited_clades_\"+str(date)+\".pkl\")\n",
    "    clade = \"clade_out\"\n",
    "    file = parse_tree_paths(df, clade)\n",
    "    file.to_csv(\"lineagePaths_edited_\"+str(date)+\".tsv\", sep=\"\\t\", index=False)\n",
    "    file.to_pickle(\"lineagePaths_edited_\"+str(date)+\".pkl\")\n",
    "    create_lineage_tree_for_itol()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the formatted files from Usher tree - we need to parse the information to be used by Cov-Dist to compare wastewater samples with SARS-Cov-2 lineages\n",
    "The bellow python script prepares the tsv file to be used the Cov-dist as well as the metadata tsv to be combined with wastewater metadata for plotting.\n",
    "The current script focuses only on Delta and Omicron lineages - OBS: The code needs to be updated to account for name aliases that continue to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "version =sys.argv[1]\n",
    "\n",
    "\n",
    "data = pd.read_pickle(\"/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/Usher_processing/\"+version+\"/lineagePaths_edited_\"+version+\".pkl\") #, sep=\"\\t\", header=None, names=(\"SNV\", \"VOC\"))\n",
    "data = data.explode(\"SNVs\")\n",
    "\n",
    "lineages = []\n",
    "ref_id_list = []\n",
    "SNV = []\n",
    "ref = []\n",
    "alt =[]\n",
    "pos = []\n",
    "new_data = pd.DataFrame()\n",
    "metadata = pd.DataFrame()\n",
    "for i, row in data.iterrows():\n",
    "    if row[\"Lineage\"].startswith(\"AY.\") or row[\"Lineage\"].startswith(\"BA.\") or row[\"Lineage\"] == \"B.1.617.2\" or row[\"Lineage\"] == \"B.1.1.529\" \\\n",
    "        or row[\"Lineage\"].startswith(\"BE.\") or row[\"Lineage\"].startswith(\"BF.\") or row[\"Lineage\"].startswith(\"BK.\") or row[\"Lineage\"].startswith(\"BJ.\") \\\n",
    "            or row[\"Lineage\"].startswith(\"BH.\") or row[\"Lineage\"].startswith(\"BG.\") or row[\"Lineage\"].startswith(\"BD.\") or row[\"Lineage\"].startswith(\"BC.\"):\n",
    "        SNV.append(row[\"SNVs\"])\n",
    "        lineages.append(row[\"Lineage\"])\n",
    "        ref_id = \"NC_045512.2\"\n",
    "        ref_id_list.append(ref_id)\n",
    "        ref.append(row[\"SNVs\"][0])\n",
    "        alt.append(row[\"SNVs\"][-1])\n",
    "        pos.append(row[\"SNVs\"][1:-1])\n",
    "\n",
    "new_data[\"Ref_id\"] = ref_id_list\n",
    "new_data[\"SNV\"] = SNV\n",
    "new_data[\"Ref\"] = ref\n",
    "new_data[\"Pos\"] = pos\n",
    "new_data[\"Alt\"] = alt\n",
    "new_data[\"VOC\"] = lineages\n",
    "\n",
    "lineages_names = list(set(lineages))\n",
    "metadata[\"names\"] = lineages_names\n",
    "type=[]\n",
    "date=[]\n",
    "location=[]\n",
    "for i,row in metadata.iterrows():\n",
    "    if row['names'].startswith(\"AY.\") or row[\"names\"]==\"B.1.617.2\":\n",
    "        type.append(\"Delta\")\n",
    "        location.append(\"Delta\")\n",
    "        date.append(\"2021-07-01\")\n",
    "    if row['names'].startswith(\"BA.\") or row[\"names\"]==\"B.1.1.529\" or row[\"names\"].startswith(\"BE.\") or row[\"names\"].startswith(\"BF.\") or row[\"names\"].startswith(\"BK.\") or row[\"names\"].startswith(\"BJ.\") \\\n",
    "            or row[\"names\"].startswith(\"BH.\") or row[\"names\"].startswith(\"BG.\") or row[\"names\"].startswith(\"BD.\") or row[\"names\"].startswith(\"BC.\"):\n",
    "        type.append(\"Omicron\")\n",
    "        location.append(\"Omicron\")\n",
    "        date.append(\"2021-12-01\")\n",
    "    \n",
    "metadata[\"type\"] = type\n",
    "metadata[\"location\"] = location\n",
    "metadata[\"date\"] = date\n",
    "\n",
    "new_data.to_csv(\"pcoa_snvs_formatted_\"+str(version)+\"_updated.tsv\", sep=\"\\t\", index=None)\n",
    "metadata.to_csv(\"metadata_voc_snvs_\"+str(version)+\"_updated.tsv\", sep=\"\\t\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
