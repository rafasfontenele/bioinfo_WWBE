{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing of GISAID data - downloaded sequences in fasta and metadata in tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "dataset=$1\n",
    "step=$2\n",
    "\n",
    "fasta=\"/gpfs/gsfs12/users/Irp-jiang/share/covid_data/GISAID/${1}/sequences.fasta\"\n",
    "metadata=\"/gpfs/gsfs12/users/Irp-jiang/share/covid_data/GISAID/${1}/metadata.tsv\"\n",
    "\n",
    "if [ $step == \"1\" ]\n",
    "then\n",
    "    mkdir \"/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/$1\"\n",
    "    mkdir \"/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/$1/01.processing\"\n",
    "    cd \"/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/$1/01.processing\"\n",
    "    module load seqtk seqkit\n",
    "    seqkit fx2tab -j 56 $fasta > sequences.tsv\n",
    "    sort -k1,1 sequences.tsv > sequences_sort.tsv\n",
    "    awk '{print $1\"|\"$4\"|\"$16\"\\t\"$3}' FS=\"\\t\" $metadata |sed '1d'|sort -k1,1 -S 80% --parallel 56 > name.tsv\n",
    "    cut -f1 name.tsv|uniq -d >name.d\n",
    "    fgrep -f name.d -w name.tsv|cut -f 2 > redo.list\n",
    "    paste name.tsv sequences_sort.tsv|fgrep -f redo.list -w -v |cut -f 2,4|seqkit -j 56 tab2fx >sequences.rename.fa\n",
    "fi\n",
    "if [ $step == \"2\" ]\n",
    "then \n",
    "    # Download sequences from the redo.list and save as redo_sequences.fasta before running step 2\n",
    "    cd \"/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/$1/01.processing\"\n",
    "    module load seqtk seqkit\n",
    "    seqkit replace -j 56 -p \"^(.+)\\|(.+)\\|(.+)$\" -r \"\\${2}\" redo_sequences.fasta > sequences.add.fa\n",
    "    cat sequences.rename.fa sequences.add.fa >sequences.acc.fa\n",
    "    seqkit fx2tab sequences.add.fa -n|cat - redo.list |sort |uniq -u > remove.list\n",
    "    module load seqkit\n",
    "    rm sequences.rename.fa sequences.add.fa\n",
    "    rm -rf sequences.tsv name.tsv name.d sequences_sort.tsv\n",
    "    seqkit split sequences.acc.fa -s 50000 -O split\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#!bin/bash\n",
    "#This bash script will set the folders and files to run Nextclade and Pangolin at the same time through swarm\n",
    "#variables\n",
    "wd=$(pwd)\n",
    "version=$1\n",
    "path=\"/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/\"\n",
    "\n",
    "# going into the versiond (date)\n",
    "cd $path$version\n",
    "\n",
    "#02.Nextclade\n",
    "#create folder\n",
    "\n",
    "mkdir 02.nextclade\n",
    "cd 02.nextclade\n",
    "\n",
    "#copy the updated run_nextclade.sh to be used \n",
    "cp $wd/run_nextclade.sh $path$version/02.nextclade\n",
    "\n",
    "#run nextclade in split files - creates output file for each split file \n",
    "# create swarm file using split X \n",
    "for file in $path$version/01.processing/split/*; \n",
    "do\n",
    "    base=$(echo $file | cut -d \"/\" -f 12 | cut -d \".\" -f 1,2,3)\n",
    "    echo \"bash run_nextclade.sh \"$base\" \"$version >> run.swarm\n",
    "done\n",
    "\n",
    "# run nextclade swarm\n",
    "swarm -f run.swarm -t 32 -g 80\n",
    "\n",
    "cd ..\n",
    "\n",
    "#03.Pangolin\n",
    "# run pangolin\n",
    "\n",
    "mkdir 03.pangolin\n",
    "cd 03.pangolin\n",
    "\n",
    "#copy the updated run_pangolin.sh to be used\n",
    "cp $wd/run_pangolin.sh $path$version/03.pangolin\n",
    "\n",
    "#this step needs to be done in split files - use the same strategy as nextclade\n",
    "#create swarm file using split X \n",
    "for file in $path$version/01.processing/split/*; \n",
    "do\n",
    "    base=$(echo $file | cut -d \"/\" -f 12 | cut -d \".\" -f 1,2,3)\n",
    "    echo \"bash run_pangolin.sh \"$base\" \"$version >> run.swarm\n",
    "done\n",
    "\n",
    "# run pangolin swarm\n",
    "swarm -f run.swarm -t 32 -g 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# run_pangolin.sh\n",
    "num=$1\n",
    "version=$2\n",
    "wd=$(pwd)\n",
    "module load singularity\n",
    "singularity run /gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/auxiliar_files/pangolin/pangolin_4.1.2-pdata-1.13.sif pangolin --outfile ${num}.lineage_report.csv -t 32 /gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/${version}/01.processing/split/${num}.fa\n",
    "sleep 10\n",
    "\n",
    "\n",
    "# run_nextclade.sh\n",
    "\n",
    "num=$1\n",
    "version=$2\n",
    "wd=$(pwd)\n",
    "module load singularity\n",
    "singularity run /gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/auxiliar_files/nextclade/nextclade_2.4.0.sif nextclade run \\\n",
    "   --output-all=${wd}/output/ \\\n",
    "   --in-order \\\n",
    "   --input-dataset=/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/auxiliar_files/nextclade/data/sars-cov-2/ \\\n",
    "   --output-selection=tsv,csv \\\n",
    "   --output-basename=${num}.nextclade \\\n",
    "   /gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/${version}/01.processing/split/${num}.fa\n",
    "sleep 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "module load datamash\n",
    "\n",
    "#variables\n",
    "wd=$(pwd)\n",
    "version=$1\n",
    "frequency=$2\n",
    "path=\"/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/\"\n",
    "\n",
    "# going into the versiond (date)\n",
    "cd $path$version\n",
    "#organize log files\n",
    "mkdir $path$version/02.nextclade/log\n",
    "mv $path$version/02.nextclade/swarm* $path$version/02.nextclade/log/\n",
    "\n",
    "mkdir $path$version/03.pangolin/log\n",
    "mv $path$version/03.pangolin/swarm* $path$version/03.pangolin/log/\n",
    "\n",
    "#merge files from Nextclade and Pangolin output\n",
    "\n",
    "# merge and select Nextclade\n",
    "awk 'FNR==1 && NR!=1{next;}{print}' $path$version/02.nextclade/output/*.tsv > $path$version/02.nextclade/output/nextclade.tsv\n",
    "\n",
    "#get the samples that passed filters\n",
    "dos2unix $path$version/02.nextclade/output/nextclade.tsv\n",
    "\n",
    "#This was valid before the Nextclade v.1.10.2\n",
    "#awk 'NR==1||$4==\"good\" && $28==\"good\" && $32==\"good\" && $37==\"good\" && $41==\"good\" && $48==\"good\" && $52==\"good\"' FS=$'\\t' $path$version/02.nextclade/output/nextclade.tsv > $path$version/02.nextclade/nextclade.selected.tsv\n",
    "\n",
    "#new collumns after update to nextclade v.1.11.0\n",
    "awk 'NR==1||$5==\"good\" && $38==\"good\" && $42==\"good\" && $47==\"good\" && $51==\"good\" && $58==\"good\" && $62==\"good\"' FS=$'\\t' $path$version/02.nextclade/output/nextclade.tsv > $path$version/02.nextclade/nextclade.selected.tsv\n",
    "\n",
    "#Concatanate de pangolin results:\n",
    "awk '(NR == 1) || (FNR > 1)' $path$version/03.pangolin/*.csv > $path$version/03.pangolin/lineage_report.csv\n",
    "\n",
    "#get the info from samples that passed filter - OLD PANGOLIN - before May 2022 updates\n",
    "#awk '$12==\"passed_qc\"{print $1\"\\t\"$2}' FS=\",\" $path$version/03.pangolin/lineage_report.csv |sort -k1,1 > $path$version/03.pangolin/acc_pangolin.tsv\n",
    "\n",
    "#get the info from samples that passed filter\n",
    "awk '$14==\"pass\"{print $1\"\\t\"$2}' FS=\",\" $path$version/03.pangolin/lineage_report.csv |sort -k1,1 > $path$version/03.pangolin/acc_pangolin.tsv\n",
    "\n",
    "#04.refine\n",
    "\n",
    "mkdir 04.refine\n",
    "\n",
    "awk 'NR>1' $path$version/02.nextclade/nextclade.selected.tsv |sort -k1,1 |join -1 1 -2 1 $path$version/03.pangolin/acc_pangolin.tsv - -t $'\\t'  > $path$version/04.refine/full_table.tsv\n",
    "cat $path$version/04.refine/full_table.tsv | sort -k1,1 -u > $path$version/04.refine/full_table_nodup.tsv\n",
    "\n",
    "\n",
    "#05.sort_SNVs\n",
    "\n",
    "mkdir 05.sort_SNVs\n",
    "cd 05.sort_SNVs\n",
    "cp $wd/get_prevalence.py $path$version/05.sort_SNVs\n",
    "\n",
    "echo -e \"sequence\\tlineage\\tsubstitutions\\tdeletions\\tinsertions\\tprivateNucMutations.reversionSubstitutions\\tprivateNucMutations.labeledSubstitutions\\tprivateNucMutations.unlabeledSubstitutions\" > $path$version/05.sort_SNVs/full_table_info.tsv\n",
    "cat $path$version/04.refine/full_table_nodup.tsv | cut -f 1,2,17,18,19,20,21,22 >> $path$version/05.sort_SNVs/full_table_info.tsv\n",
    "\n",
    "#take out any empy SNPs lines\n",
    "#add one nucleotide per line\n",
    "#get snps info\n",
    "awk '{print $1,$2\",\"$3}' FS=\"\\t\" OFS=\"\\t\" $path$version/05.sort_SNVs/full_table_info.tsv | awk '{for(i=2;i<=NF;i++){print $1\"\\t\"$i}}' FS=\",\" OFS=\"\\t\" > $path$version/05.sort_SNVs/full_table_info_nuc.tsv\n",
    "awk -F '\\t' '$3 != \"\"' full_table_info_nuc.tsv > full_table_info_nuc_nonNAN.tsv\n",
    "#get deletion info\n",
    "awk '{print $1,$2\",\"$4}' FS=\"\\t\" OFS=\"\\t\" $path$version/05.sort_SNVs/full_table_info.tsv | awk '{for(i=2;i<=NF;i++){print $1\"\\t\"$i}}' FS=\",\" OFS=\"\\t\" > $path$version/05.sort_SNVs/full_table_info_del.tsv\n",
    "awk -F '\\t' '$3 != \"\"' full_table_info_del.tsv > full_table_info_del_nonNAN.tsv\n",
    "#get insertion info\n",
    "awk '{print $1,$2\",\"$5}' FS=\"\\t\" OFS=\"\\t\" $path$version/05.sort_SNVs/full_table_info.tsv | awk '{for(i=2;i<=NF;i++){print $1\"\\t\"$i}}' FS=\",\" OFS=\"\\t\" > $path$version/05.sort_SNVs/full_table_info_ins.tsv\n",
    "awk -F '\\t' '$3 != \"\"' full_table_info_ins.tsv > full_table_info_ins_nonNAN.tsv\n",
    "\n",
    "#merge snps, deltetions and insertios\n",
    "cat full_table_info_nuc_nonNAN.tsv full_table_info_del_nonNAN.tsv full_table_info_ins_nonNAN.tsv > full_table_info_all.tsv\n",
    "\n",
    "#merge deletions and insertion to use SNVS from USHER tree\n",
    "cat full_table_info_del_nonNAN.tsv full_table_info_ins_nonNAN.tsv > full_table_info_ins_del.tsv\n",
    "\n",
    "#get count of variants per lineage\n",
    "cat $path$version/05.sort_SNVs/full_table_info_all.tsv | datamash --header-out --sort groupby 3,2 count 1 > $path$version/05.sort_SNVs/full_table_info_all_permut.tsv\n",
    "cat $path$version/05.sort_SNVs/full_table_info_ins_del.tsv | datamash --header-out --sort groupby 3,2 count 1 > $path$version/05.sort_SNVs/full_table_info_ins_del_permut.tsv\n",
    "\n",
    "#get count of total sequences per lineage\n",
    "cat $path$version/05.sort_SNVs/full_table_info.tsv | datamash --header-out --sort groupby 2 countunique 1 > $path$version/05.sort_SNVs/full_table_info_countseqs.tsv\n",
    "\n",
    "#get lineage prevalence using above files\n",
    "python $path$version/05.sort_SNVs/get_prevalence.py full_table_info_countseqs.tsv full_table_info_all_permut.tsv full_table_info_all_final.tsv\n",
    "python $path$version/05.sort_SNVs/get_prevalence.py full_table_info_countseqs.tsv full_table_info_ins_del_permut.tsv full_table_info_ins_del_final.tsv\n",
    "\n",
    "#filter data based on frequency within the lineage - only did it for snvs info since deletions and isertion are already rare\n",
    "cat $path$version/05.sort_SNVs/full_table_info_all_final.tsv | awk -v start=\"${frequency}\" -v end=\"100.0\" -F\"\\t\" '$5>=start && $5<=end' > $path$version/05.sort_SNVs/full_table_info_all_final_gtr${frequency:0:2}.tsv\n",
    "cat $path$version/05.sort_SNVs/full_table_info_ins_del_final.tsv | awk -v start=\"${frequency}\" -v end=\"100.0\" -F\"\\t\" '$5>=start && $5<=end' > $path$version/05.sort_SNVs/full_table_info_ins_del_final_gtr${frequency:0:2}.tsv\n",
    "\n",
    "#put lineage SNPS per line\n",
    "cat $path$version/05.sort_SNVs/full_table_info_all_final_gtr${frequency:0:2}.tsv | datamash --sort groupby 1 count 2 collapse 2 > $path$version/05.sort_SNVs/full_table_info_all_final_gtr${frequency:0:2}_perlin.tsv\n",
    "cat $path$version/05.sort_SNVs/full_table_info_all_final_gtr${frequency:0:2}.tsv | datamash --sort groupby 2 count 1 collapse 1 > $path$version/05.sort_SNVs/full_table_info_all_final_gtr${frequency:0:2}_listsnvs.tsv\n",
    "cat $path$version/05.sort_SNVs/full_table_info_ins_del_final_gtr${frequency:0:2}.tsv | datamash --sort groupby 1 count 2 collapse 2 > $path$version/05.sort_SNVs/full_table_info_ins_del_final_gtr${frequency:0:2}_perlin.tsv\n",
    "cat $path$version/05.sort_SNVs/full_table_info_ins_del_final_gtr${frequency:0:2}.tsv | datamash --sort groupby 2 count 1 collapse 1 > $path$version/05.sort_SNVs/full_table_info_ins_del_final_gtr${frequency:0:2}_listsnvs.tsv\n",
    "#set-up for lineage assingment\n",
    "cd ..\n",
    "mkdir 06.lineage_assingment\n",
    "cd 06.lineage_assingment\n",
    "cp $path$version/05.sort_SNVs/full_table_info_ins_del_final_gtr${frequency:0:2}_listsnvs.tsv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "wd=$(pwd)\n",
    "version=$1\n",
    "usher_date=$2\n",
    "path=\"/gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/\"\n",
    "\n",
    "#update lineages\n",
    "cd /data/salgadofontenr2/pango-designation/\n",
    "git pull\n",
    "cd  $wd\n",
    "\n",
    "cp /data/salgadofontenr2/pango-designation/lineage_notes.txt $path$version/06.lineage_assingment\n",
    "cp /data/salgadofontenr2/pango-designation/pango_designation/alias_key.json $path$version/06.lineage_assingment\n",
    "cp /gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/${version}/05.sort_SNVs/full_table_info_ins_del_final_gtr75_listsnvs.tsv $path$version/06.lineage_assingment\n",
    "cp /gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/Usher_processing/${usher_date}/lineagePaths_edited_${usher_date}.pkl $path$version/06.lineage_assingment\n",
    "cp /gpfs/gsfs12/users/Irp-jiang/share/rafa_data/GISAID_processing_WWBE/Usher_processing/${usher_date}/lineagePaths_edited_clades_${usher_date}.pkl $path$version/06.lineage_assingment\n",
    "\n",
    "# conda activate cov-dist\n",
    "\n",
    "cd $path$version/06.lineage_assingment\n",
    "cat lineage_notes.txt | cut -f 1 | sed '/^*/d' > lineage_list.txt\n",
    "python $wd/get_derivedsnvs.py $version full_table_info_ins_del_final_gtr75_listsnvs.tsv lineagePaths_edited_${usher_date}.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python script to obtain derived SNVs per lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working function but no nested dictionaries\n",
    "#!/usr/bin/env python\n",
    "from numpy.lib.utils import info\n",
    "import pandas as pd\n",
    "from ete3 import Tree\n",
    "import pickle\n",
    "import sys\n",
    "import json\n",
    "\n",
    "#date of current version\n",
    "version = sys.argv[1]\n",
    "#name of the file coming from gisaid with sequence insertions and deletions \"Full_table_info_ins_del_final_gtr75_listsnvs.tsv\"\n",
    "ins_del = sys.argv[2]\n",
    "# usher processes info of snvs per lineage \"lineagePaths_edited_<date>.pkl\"\n",
    "snvs = sys.argv[3]\n",
    "\n",
    "\n",
    "# Load the alias info\n",
    "with open('alias_key.json') as f:\n",
    "    d = json.load(f)\n",
    "    m = { key: value if value else key for key, value in d.items() if not type(value) is list }\n",
    "f.close()\n",
    "\n",
    "def get_pair(i):\n",
    "    l=i.split(\".\")\n",
    "    pair = set()\n",
    "    while len(l) > 1:\n",
    "        suf = l.pop()\n",
    "        pre = \".\".join(l)\n",
    "        if len(l) == 1:\n",
    "            pair.add((m[pre],pre+\".\"+suf))\n",
    "        else:\n",
    "            pair.add((pre,pre+\".\"+suf))\n",
    "    return pair\n",
    "\n",
    "# Load parent children key from alias_key\n",
    "data = [line.strip() for line in open(\"lineage_list.txt\", 'r')]\n",
    "t={(\"root\",\"A\"),(\"root\",\"B\")}\n",
    "for i in data:\n",
    "    t.update(get_pair(i))\n",
    "\n",
    "\n",
    "tree = Tree.from_parent_child_table(t)\n",
    "\n",
    "#merge snvs from Usher and ins/deletion derived from GISAID \n",
    "file_ins_del = pd.read_csv(ins_del, sep=\"\\t\", header=None, names=[\"Lineage\",\"root_id\", \"SNVs\"])\n",
    "file_ins_del.set_index(\"Lineage\", inplace=True)\n",
    "file_snvs = pd.read_pickle(snvs)\n",
    "file_snvs.set_index(\"Lineage\", inplace=True)\n",
    "for i in file_snvs.index:\n",
    "    for index in file_ins_del.index:\n",
    "        if i == index:\n",
    "            list_to_add=file_ins_del.loc[index, \"SNVs\"].split(\",\")\n",
    "            old_list=file_snvs.loc[i, \"SNVs\"]\n",
    "            new_list = old_list + list_to_add\n",
    "            file_snvs.at[i,\"SNVs\"] = new_list\n",
    "\n",
    "#function for store info in a dataframe\n",
    "def store_info(file_snvs,tree):\n",
    "    data = pd.DataFrame()\n",
    "    lineages_list=[]\n",
    "    parents_list=[]\n",
    "    child_list = []\n",
    "    snvs_list=[]\n",
    "    derived_snvs_list=[]\n",
    "    for i ,row in file_snvs.iterrows():\n",
    "        sample = i #row['Lineage']\n",
    "        sample_snvs = row[\"SNVs\"] #row[\"SNVs\"].split(\",\") #when not using usher\n",
    "        sample_snvs = list(set(sample_snvs))\n",
    "        if sample not in lineages_list:\n",
    "            children, parent, sisters =  get_relationship(sample,tree)\n",
    "            lineages_list.append(sample)\n",
    "            parents_list.append(parent)\n",
    "            child_list.append(children)\n",
    "            snvs_list.append(snvs_lineage_all(sample_snvs, file_snvs)) # changed to get info of snvs shared by lineage\n",
    "            list_snvs = get_defining_snvs(sample, parent, file_snvs) #add \n",
    "            derived_snvs_list.append(snvs_lineage_sisters(list_snvs, sisters , file_snvs, sample))\n",
    "    data[\"lineage\"] = lineages_list\n",
    "    data['parent'] = parents_list\n",
    "    data['child'] = child_list\n",
    "    data[\"snvs\"] = snvs_list\n",
    "    data[\"derived_snvs\"] =derived_snvs_list\n",
    "    return data\n",
    "\n",
    "def check_missing_parent(file_snvs, tree):\n",
    "    temp_df = pd.DataFrame()\n",
    "    lineages_to_check= [lin for lin in file_snvs.index] #file_snvs[\"Lineage\"]]\n",
    "    to_add=[]\n",
    "    for i, row in file_snvs.iterrows():\n",
    "        lineage = i #row[\"Lineage\"]\n",
    "        child, parent, sister = get_relationship(lineage, tree)\n",
    "        if parent not in lineages_to_check and parent != \"root\" and parent != \"B\" and parent != \"\":\n",
    "            to_add.append(parent)\n",
    "    to_add=list(set(to_add))\n",
    "    if to_add:\n",
    "        for lin in to_add:\n",
    "            snvs_list=[]\n",
    "            child, parent, sister = get_relationship(lin, tree)\n",
    "            child_check = [ch for ch in child if ch in lineages_to_check]\n",
    "            child_num=len(child_check)\n",
    "            for children in child_check:\n",
    "                if children in file_snvs.index:\n",
    "                    info = file_snvs.loc[children,\"SNVs\"]\n",
    "                    snvs_list += info\n",
    "            snvs_list_shared= [snv for snv in snvs_list if snvs_list.count(snv) == child_num]\n",
    "            temp_df = temp_df.append({\"Lineage\": lin, \"number\": 0, \"SNVs\": snvs_list_shared}, ignore_index=True)\n",
    "    temp_df = temp_df.set_index(\"Lineage\")\n",
    "    file_snvs = file_snvs.append(temp_df)\n",
    "    return file_snvs\n",
    "\n",
    "\n",
    "#function to get relationship info\n",
    "def get_relationship(lineage,tree):\n",
    "    child =[]\n",
    "    sisters =[]\n",
    "    parent = \"\"\n",
    "    for node in tree.traverse():\n",
    "        if node.name == lineage:\n",
    "            c = node.get_children()\n",
    "            parent = (node.up).name\n",
    "            s = node.get_sisters()\n",
    "            for kid in c:\n",
    "                child.append(kid.name)\n",
    "            for sis in s:\n",
    "                sisters.append(sis.name)\n",
    "    return child ,parent, sisters\n",
    "\n",
    "#function to get derived SNVs\n",
    "def get_defining_snvs(lineage, parent, file_snvs):\n",
    "    parent_snvs_list = []# for when a parent is missing from the data\n",
    "    for i,row in file_snvs.iterrows():\n",
    "        if i == lineage: #row[\"Lineage\"]\n",
    "            lineage_snvs_list = row[\"SNVs\"] #row[\"SNVs\"].split(\",\") #when not using usher\n",
    "            lineage_snvs_list = list(set(lineage_snvs_list))\n",
    "        if i == parent: #row[\"Lineage\"]\n",
    "            parent_snvs_list = row[\"SNVs\"] #row[\"SNVs\"].split(\",\") #when not using usher\n",
    "            parent_snvs_list = list(set(parent_snvs_list))\n",
    "    final_snvs_list = [snv for snv in lineage_snvs_list if snv not in parent_snvs_list]\n",
    "    return final_snvs_list\n",
    "\n",
    "#function to get lineages associated with derived snvs\n",
    "def snvs_lineage_sisters(list_snvs, sisters, file_snvs, sample):\n",
    "    snv_lin_list = []\n",
    "    for snvs in list_snvs:\n",
    "        info = {}\n",
    "        info[snvs] =[]\n",
    "        for i,row in file_snvs.iterrows():\n",
    "            if snvs in row[\"SNVs\"]: #row[\"SNVs\"].split(\",\"): #when not using usher\n",
    "                if i in sisters or i == sample: #row[\"Lineage\"]\n",
    "                    info[snvs].append(i)\n",
    "        snv_lin_list.append(info)\n",
    "    return snv_lin_list\n",
    "\n",
    "def snvs_lineage_all(list_snvs, file_snvs):\n",
    "    snv_lin_list = []\n",
    "    for snvs in list_snvs:\n",
    "        info = {}\n",
    "        info[snvs] =[]\n",
    "        for i,row in file_snvs.iterrows():\n",
    "            if snvs in row[\"SNVs\"]: #row[\"SNVs\"].split(\",\"): #when not using usher\n",
    "                info[snvs].append(i) #row[\"Lineage\"]\n",
    "        snv_lin_list.append(info)\n",
    "    return snv_lin_list\n",
    "\n",
    "\n",
    "\n",
    "checked_file = check_missing_parent(file_snvs,tree)\n",
    "result = store_info(checked_file,tree)\n",
    "result.to_pickle(\"child_parent_info_\"+version+\"_all.pkl\") # to load directly into lineage_assingment\n",
    "#result.to_json(\"child_parent_snv_info_delta.json\")\n",
    "result.to_csv(\"child_parent_info_\"+version+\"_all.tsv\", sep=\"\\t\", index=False) #output_file argument \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
